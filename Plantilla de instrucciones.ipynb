{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plantilla de desarrollo para primer examen parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pautas:**\n",
    "- La presente plantilla es un EJEMPLO de cómo ordenar el código de tu examen\n",
    "- Tienes la libertad DE AGREGAR todos los métodos y secciones en el examen que consideres necesarias\n",
    "- Realizar el desarrollo por medio de métodos, por ejemplo, ReadInfo(), TrainModel(), etc \n",
    "- Los métodos deberán de estar lo mas claro y modularizados que sea posible\n",
    "- Realizar la documentación de cada método por medio de comentarios y DocStrings \n",
    "- Deberás de utilizar un modelo de ML o algún ensamble de os mismos (SVC, DT, NB, KNN, etc)\n",
    "- Recuerda que puedes usar un split de los datos para entrenamiento y validación\n",
    "- Puedes revisar la documentación de Sklearn, o la librría que decidas utilizar para entender los parámetros de entrenamiento de los modelos\n",
    "- NO está permitido el uso de modelos de Deep Learning (DNN, CNN, LSTM, etc.) NI el uso de embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para manejo de Dataframes\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Librerías para trabajar con el texto\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Librerías para entrenar una máquina de soporte vectorial (Ejemplo)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Librerías para trabajar con métricas\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí cargamos la información del DataSet de entrenamiento\n",
    "def ReadCorpus(path):\n",
    "    \"\"\"Este método lee los de datos del corpus y los pasa a un dataFrame\n",
    "\n",
    "    Args:\n",
    "        path (string): Ubicación del archivo de entrada (Corpus)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Elementos en el DataSet:\", len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega lo que consideres necesario aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserta lo que consideres necesario aquí, por ejemplo\n",
    "def Preprocess(df):\n",
    "    \"\"\"Método para preprocesar el texto\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): Dataframe a aplicar transformaciones\n",
    "\n",
    "    Returns:\n",
    "        dataframe: Dataframe transformado\n",
    "    \"\"\"\n",
    "    df['title'] = df['title'].apply(lambda x: x.lower())\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo lo que necesites para entrenar tu modelo\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "model = LinearSVC()\n",
    "\n",
    "\n",
    "def TrainModel(X, y):\n",
    "    \"\"\"Este método realiza el entrenamiento del modelo (Ejemplo)\n",
    "\n",
    "    Args:\n",
    "        X (list): Lista con los textos a transformar\n",
    "        y (list): Lista con los valores de y (Salida)\n",
    "\n",
    "    Returns:\n",
    "        model: Modelo entrenado\n",
    "    \"\"\"\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidateModel(Y_test, Predicciones):\n",
    "    # Impresión de matriz de confusión\n",
    "    # print(\"Matriz de confusión:\")\n",
    "    # print(confusion_matrix(Y_test, Predicciones))\n",
    "\n",
    "    # Impresión de procentaje de Accuracy del modelo\n",
    "    print(\"\\nAccuracy del modelo: \")\n",
    "    print(metrics.accuracy_score(Y_test, Predicciones))\n",
    "\n",
    "    # Impresión de las métricas para el modelo\n",
    "    print(\"\\nMétricas de evaluación:\")\n",
    "    print(classification_report(Y_test, Predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de todo el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos en el DataSet: 16823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mi24830/miniconda3/envs/nlp_up/lib/python3.9/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy del modelo: \n",
      "0.7527488855869242\n",
      "\n",
      "Métricas de evaluación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   clickbait       0.37      0.34      0.35       672\n",
      "        news       0.84      0.86      0.85      2693\n",
      "\n",
      "    accuracy                           0.75      3365\n",
      "   macro avg       0.60      0.60      0.60      3365\n",
      "weighted avg       0.74      0.75      0.75      3365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mi24830/miniconda3/envs/nlp_up/lib/python3.9/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargamos la información y creamos un DataFrame\n",
    "path = 'DataSetClickBait.csv'\n",
    "df = ReadCorpus(path)\n",
    "\n",
    "# Preprocesamiento\n",
    "df_pre = Preprocess(df)\n",
    "\n",
    "# Lectura y split de los datos\n",
    "X = df_pre['title'].values.tolist()\n",
    "y = df_pre['label'].values.tolist()\n",
    "\n",
    "X = count_vect.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "model = TrainModel(X_train, y_train)\n",
    "\n",
    "# Impresión de métricas\n",
    "Predicciones = model.predict(X_test)\n",
    "ValidateModel(y_test, Predicciones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle para guardar modelos\n",
    "import pickle\n",
    "\n",
    "filename = \"model_Nombre_chido.pickle\"\n",
    "\n",
    "# Guardar el modelo\n",
    "pickle.dump(model, open(filename, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del modelo (Parte mas importante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline(input_file, model):\n",
    "    # Cargamos la información y creamos un DataFrame\n",
    "    df = ReadCorpus(path)\n",
    "\n",
    "    # Preprocesamiento\n",
    "    df_pre = Preprocess(df)\n",
    "\n",
    "    # Lectura y split de los datos\n",
    "    X = df_pre['title'].values.tolist()\n",
    "    y = df_pre['label'].values.tolist()\n",
    "\n",
    "    X = count_vect.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    model = TrainModel(X_train, y_train)\n",
    "\n",
    "    # Impresión de métricas\n",
    "    Predicciones = model.predict(X_test)\n",
    "    ValidateModel(y_test, Predicciones)\n",
    "\n",
    "\n",
    "# Prueba para calificación del examen\n",
    "input_file = 'DataSetClickBait.csv'\n",
    "Pipeline(input_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
