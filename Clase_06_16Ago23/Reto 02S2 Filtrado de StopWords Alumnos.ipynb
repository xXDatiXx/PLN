{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC4JSh43njBM"
   },
   "source": [
    "# Filtrado de StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7qZxrTO1njBQ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Importar librerías de NLTK\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m RegexpTokenizer\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtreebank\u001b[39;00m \u001b[39mimport\u001b[39;00m TreebankWordDetokenizer\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Importar librerías de NLTK\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsenLaSAnjBe"
   },
   "outputs": [],
   "source": [
    "# Asignación de StopWords predefinidas para idioma Español\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('spanish')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfn-TAvanjBn"
   },
   "outputs": [],
   "source": [
    "# Creamos un diccionario con el formato\n",
    "# {Veces_que_aparece_la_palabra: [Palabra1, Palbra2, Palabra3, etc..]}\n",
    "from os import listdir\n",
    "Palabras = []\n",
    "\n",
    "path = 'Textos_Stopwords/'\n",
    "\n",
    "for File in listdir(path):\n",
    "    # Escribir la RUTA COMPLETA de cada archivo\n",
    "    with open(path + File) as Text:\n",
    "        # LEER el texto y pasar todo a minúsculas y reemplazar signos de puntuación \n",
    "        Texto = Text.read().lower()\n",
    "        Texto = Texto.replace('.','').replace(',','').replace(';','').replace('-','')\n",
    "        Texto = Texto.replace('¿','').replace('?','').replace('¡','').replace('!','')\n",
    "        Texto = Texto.replace('(','').replace(')','').replace('—','')\n",
    "        # Solo se agregan las que no sean StopWords\n",
    "        for palabra in Texto.split():\n",
    "            if(palabra not in stop_words):\n",
    "                Palabras.append(palabra)\n",
    "\n",
    "#Diccionario = {1: [pedro,  juan, Albus, Cadnis...],\n",
    " #              2: [Harry]} #Cuardamos las palabras\n",
    "\n",
    "# Crear el diccionario con las frecuencias como claves y listas de palabras \n",
    "# correspondientes a cada frecuencia como valores\n",
    "Palabras_unicas = {}\n",
    "for unica in set(Palabras):\n",
    "    Frec = Palabras.count(unica)\n",
    "    # Preguntar si existe el elemento en el diccionario y si no, agregarlo\n",
    "    if(Palabras_unicas.get(Frec) == None):\n",
    "        Palabras_unicas.setdefault(Frec, [unica]) # Agregar el elemento\n",
    "    else:\n",
    "        Palabras_unicas[Frec].append(unica)\n",
    "print(Palabras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM1KN9HZnjB3"
   },
   "outputs": [],
   "source": [
    "# Ploteo de la gráfica de palabras para cada frecuencia de repetición\n",
    "# Declarar la librería para plotear y los parámetros de la gráfica\n",
    "import matplotlib._____ as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "# Extraer la cantidad de palabras de cada categoría\n",
    "Frecuencias = []\n",
    "for Lista in Palabras_unicas._____():\n",
    "    Frecuencias.append(len(Lista))\n",
    "\n",
    "# Parámetros de ploteo\n",
    "plt.bar(Palabras_unicas._____(), Frecuencias, color=['cornflowerblue', 'lightblue', 'steelblue'])  \n",
    "plt.ylabel('Palabras distintas')\n",
    "plt.xlabel('Cantidad de repeticiones')\n",
    "plt.title('Cantidad de palabras por cantidad de apariciones')\n",
    "plt.xticks(rotation=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uM6xhyytnjCJ"
   },
   "outputs": [],
   "source": [
    "# Impresión de las palabras que corresponden a cada frecuencia:\n",
    "# (Se suma +1 porque el primer índice debe ser 1 y no 0)\n",
    "for x in range(max(Palabras_unicas._____())):\n",
    "    print(\"\\nPalabras que se repiten \" + str(x+1) + \" veces:\")\n",
    "    if(Palabras_unicas.get(x+1) != None):\n",
    "        print(set(_____[x+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNGqWxLMnjDi"
   },
   "outputs": [],
   "source": [
    "# Agregar palabras adicionales (Personalizadas) al diccionario de StopWords\n",
    "\n",
    "nuevas_StopWords = ['si','no', 'hola', 'adios', 'a', 'ante', 'bajo', 'cabe', 'con', 'contra', 'de', 'desde']\n",
    "stop_words.extend(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehQoHiqHnjDx"
   },
   "outputs": [],
   "source": [
    "# Ploteo de la nueva gráfica\n",
    "import matplotlib._____ as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "# Extraer la cantidad de palabras de cada categoría\n",
    "Frecuencias = []\n",
    "for Lista in Palabras_unicas._____():\n",
    "    Frecuencias.append(len(Lista))\n",
    "\n",
    "# Parámetros de ploteo\n",
    "plt.bar(Palabras_unicas._____(), Frecuencias, color=['cornflowerblue', 'lightblue', 'steelblue'])  \n",
    "plt.ylabel('Palabras distintas')\n",
    "plt.xlabel('Cantidad de repeticiones')\n",
    "plt.title('Cantidad de palabras por cantidad de apariciones')\n",
    "plt.xticks(rotation=80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reto 02S2 Filtrado de StopWords Alumnos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
