{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N921vKRx4RIH"
   },
   "source": [
    "# Tarea 01: Corrector gramatical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebastian Fernandez Lopez <br>\n",
    "Diego Arenas Trevilla <br>\n",
    "Michelle Zelonka Carbajal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd_x9Fv4rMre"
   },
   "source": [
    "### Para esta tarea, deberás de generar un corrector gramatical que evalué 5 tipos de errores comunes, llenando los métodos que aparecen en este notebook. Deberás de utilizar la lógica adecuada para cada uno y usar el formato de docstring correspondiente para documentar el uso de cada método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7InFgho6rytt"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de formato Docstrings:\n",
    "\n",
    "def NombreFuncion(arg1, arg2, arg3):\n",
    "  \"\"\"\n",
    "  Este método sirve para... utilizando... y devuelve...\n",
    "\n",
    "  Args:\n",
    "    string arg1: Esta es una cadena de texto que...\n",
    "    int arg 2: Es un número entero que se usa para...\n",
    "    dict arg 3: Diccionario que sirve para...\n",
    "\n",
    "  Returns:\n",
    "    string: Cadena del texto ya corregido...\n",
    "  \"\"\"\n",
    "\n",
    "  # Aquí debe de ir la lógica de la función (Después de la documentación)\n",
    "  Texto = \"ola x fabor, balla usted a resar por la informasion sobre la buelta que hemos echo en la bida; aver tomado esta desición es lo que hacemos con determinación.\"\n",
    "  return Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvSGW06Rsxdq"
   },
   "source": [
    "#### Plantilla de tarea 1: Corrector gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeohFnXD4RIM"
   },
   "outputs": [],
   "source": [
    "# Importar la librería de SpaCy y su núcleo de trabajo en Español\n",
    "import spacy\n",
    "\n",
    "# Cargamos núcleo de trabajo (Español)\n",
    "pln_es = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzhE-GB64RIO"
   },
   "outputs": [],
   "source": [
    "# Módulo para correguir errores de ortografía comunes\n",
    "# Utilizando un diccionario\n",
    "# Agregar mas ejemplos al diccionario\n",
    "\n",
    "Diccionario = {'hola' : 'ola',\n",
    "               'favor': 'fabor',\n",
    "               'por':'x',\n",
    "               'rezar':'resar',\n",
    "               'información':'informasion',\n",
    "               'vaya':'balla',\n",
    "               'hecho': 'echo',\n",
    "               'vida':'bida', \n",
    "               'vuelta': 'buelta',\n",
    "               'haber':'aver',\n",
    "               'hacemos':'asemos',\n",
    "               'decisión':'desición',\n",
    "               'gracias':'grasias',\n",
    "               'saldo':'zaldo'\n",
    "               }\n",
    "\n",
    "import nltk\n",
    "def ERRORES_COMUNES(Texto):\n",
    "    tokens = nltk.word_tokenize(Texto)\n",
    "    \n",
    "    texto_corregido = Texto\n",
    "    \n",
    "    for token in tokens: \n",
    "        corregido = False\n",
    "        for clave, valor in Diccionario.items():\n",
    "            if token == valor: \n",
    "                texto_corregido = texto_corregido.replace(token,clave)\n",
    "                corregido = True\n",
    "                break #Para salir del bucle interno despues de corregir la palabra\n",
    "    return texto_corregido\n",
    "\n",
    "Texto = \"ola x fabor, balla usted a resar por la informasion sobre la buelta que hemos echo en la bida; aver tomado esta desición es lo que hacemos con determinación.\"\n",
    "\n",
    "print(ERRORES_COMUNES(Texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyiF2RVn4RIP"
   },
   "outputs": [],
   "source": [
    "# Módulo para correguir errores dentre singulares y plurales\n",
    "# Investigar si existe algún atributo en Spacy que pueda devolver dicha característica\n",
    "# O implementar alguna lógica que pueda detectar si una palabra es sing, o plural\n",
    "\n",
    "# Quiero una casas en la playa\n",
    "#autobus caries  dos martes lunes \n",
    "from spacy import displacy \n",
    "import spacy \n",
    "pln = spacy.load(\"es_core_news_lg\") \n",
    "\n",
    "def TIEMPOS_VERBALES(Texto):\n",
    "    # Documentación y lógica aquí \n",
    "    texto = pln(Texto)\n",
    "    \n",
    "    texto_corregido = Texto\n",
    "\n",
    "    \n",
    "    for i in range(len(texto)):\n",
    "        token = texto[i]        \n",
    "        if token.pos_ == \"DET\" and token.text.endswith(\"s\"):\n",
    "            if i +1 < len(texto):\n",
    "                next_token = texto[i+1]\n",
    "                if next_token.pos_ == \"NOUN\": \n",
    "                    plural = next_token.text + \"s\"\n",
    "                    texto_corregido = texto_corregido.replace(next_token.text,plural)\n",
    "        \n",
    "        if token.pos_ == \"DET\" and not token.text.endswith(\"s\"):\n",
    "            if i+1 < len(texto): \n",
    "                next_token = texto[i+1]\n",
    "                if next_token.pos_ == \"NOUN\":\n",
    "                    if next_token.text.endswith(\"s\"): #casas autobus\n",
    "                        singular = next_token.lemma_\n",
    "                        texto_corregido = texto_corregido.replace(next_token.text,singular)\n",
    "                    \n",
    "    return texto_corregido\n",
    "\n",
    "Texto= \"Quiero una casas en la playa\"\n",
    "Texto1 = \"los niño salieron a jugar al patio\"\n",
    "print(TIEMPOS_VERBALES(Texto1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZriCF1o4RIR"
   },
   "outputs": [],
   "source": [
    "# Módulo para detectar palabras repetidas\n",
    "# Palabras que se repiten repiten\n",
    "\n",
    "import nltk\n",
    "\n",
    "def PALABRA_REPETIDA(Texto):\n",
    "    # Documentación y lógica aquí\n",
    "    tokens = nltk.word_tokenize(Texto)\n",
    "    Texto_corregido = Texto\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if i+1 < len(tokens): \n",
    "            if (tokens[i] == tokens[i+1]):\n",
    "                Texto_corregido = Texto_corregido.replace(tokens[i+1],'',1)\n",
    "                Texto_corregido = Texto_corregido.replace(\"  \", \" \")\n",
    "\n",
    "    return Texto_corregido\n",
    "\n",
    "Texto = \"Palabras que se repiten repiten mucho\"\n",
    "PALABRA_REPETIDA(Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNuF3Hbc4RIS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Módulo para detectar problemas con mayúsculas y minúsculas\n",
    "# Recuerda que si una palabra son SIGLAS (Es decir, se trata de una organización\n",
    "# o lugar), NO se considera un error gramatical\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "def MAYUSC_MINUSC(Texto):\n",
    "    # Documentación y lógica aquí\n",
    "    pln_es = spacy.load(\"es_core_news_lg\")\n",
    "    tokens = pln_es(Texto)\n",
    "    Texto_corregido = Texto\n",
    "    for i, token in enumerate(tokens):\n",
    "        #print(\"Texto:\", token.text)\n",
    "        #print(\"POS\", token.pos_)\n",
    "        #print(\"ENT\", token.label_)\n",
    "        if i == 0:\n",
    "            inicio = token.text.title()\n",
    "            Texto_corregido = Texto_corregido.replace(token.text,inicio)\n",
    "       \n",
    "        if token.text == \".\" and i + 1 < len(tokens):\n",
    "            siguiente_token = tokens[i + 1]\n",
    "            correcto = siguiente_token.text.title()\n",
    "            Texto_corregido = Texto_corregido.replace(siguiente_token.text, correcto)\n",
    "            \n",
    "        if token.ent_type_ in [\"LOC\", \"ORG\",\"PROPN\"]: \n",
    "            loc = token.text.title()\n",
    "            propn = token.text.title()\n",
    "            org = token.text.upper()\n",
    "            if (token.ent_type_ == \"LOC\"): \n",
    "                Texto_corregido = Texto_corregido.replace(token.text,loc)\n",
    "            elif (token.ent_type_ == \"ORG\"):\n",
    "                Texto_corregido = Texto_corregido.replace(token.text,org)\n",
    "            elif (token.ent_type == \"PROPN\"):\n",
    "                Texto_corregido = Texto_corregido.replace(token.text,propn)\n",
    "                \n",
    "        else:\n",
    "            if not token.text.islower():\n",
    "                minus = token.text.lower()\n",
    "                Texto_corregido = Texto_corregido.replace(token.text, minus)\n",
    "                #print(token.text, token.pos_)\n",
    "    \n",
    "    return Texto_corregido\n",
    "\n",
    "Texto = \"soy de la CDMX y quiero ir a nueva york con mi peRRo. estoy emocionada. mi perro es muy juguetón\"\n",
    "MAYUSC_MINUSC(Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5EG4pz14RIT"
   },
   "outputs": [],
   "source": [
    "# Modulo para detectar nouns juntos que no son un nombre propio\n",
    "# Recuerda que \"Juega el perro gato en el parque\" es incorrecto\n",
    "# porque hay dos NOUNS juntos (perro y gato), pero el texto \"mi\n",
    "# amigo Pedro\" es correcto, sin embargo aquí se trata de un NOUN\n",
    "# seguido de un PNOUN (Nombre propio), deberás de identificar si\n",
    "# si ocurre un caso como este, o si por ejemplo, todo el nombre\n",
    "# pertenece a una persona (entidad) para validar que no sea un error\n",
    "from spacy import displacy \n",
    "import spacy \n",
    "pln = spacy.load(\"es_core_news_lg\") \n",
    "\n",
    "def NOUNS(Texto):\n",
    "    # Documentación y lógica aquí\n",
    "    tokens = pln(Texto)\n",
    "    Texto_corregido = Texto\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        print(\"Texto: \", tokens[i].text) #extrer el texto del token \n",
    "        print(\"PoS: \", tokens[i].pos_) #extraer el part of speech\n",
    "        #print(\"Lemma: \", tokens[i].lemma_) #extraer la lematización \n",
    "        #print(\"\\n\")\n",
    "        if i + 1 < len(tokens): # ADD CASE FOR WHEN DETECTED AS PROPN\n",
    "            if tokens[i].pos_  == \"NOUN\" and tokens[i+1].pos_ == \"NOUN\" or tokens[i].pos_  == \"PROPN\" and tokens[i+1].pos_ == \"PROPN\":  \n",
    "                add = \"y\"\n",
    "                noun1 = f'{add} {tokens[i+1]}'\n",
    "                Texto_corregido = Texto_corregido.replace(tokens[i+1].text, noun1)  \n",
    "\n",
    "\n",
    "    return Texto_corregido \n",
    "Texto1 = \"Juega el perro gato en el parque y yo estoy con mi amigo Pedro.\"\n",
    "Texto2 =\"La mariposa cielo es azul.\"\n",
    "Texto3 = \"Mi amigo Pedro quiere ir al cine\"\n",
    "NOUNS(Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método fuerza noun\n",
    "# Modulo para detectar nouns juntos que no son un nombre propio\n",
    "# Recuerda que \"Juega el perro gato en el parque\" es incorrecto\n",
    "# porque hay dos NOUNS juntos (perro y gato), pero el texto \"mi\n",
    "# amigo Pedro\" es correcto, sin embargo aquí se trata de un NOUN\n",
    "# seguido de un PNOUN (Nombre propio), deberás de identificar si\n",
    "# si ocurre un caso como este, o si por ejemplo, todo el nombre\n",
    "# pertenece a una persona (entidad) para validar que no sea un error\n",
    "\n",
    "import spacy \n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "pln = spacy.load(\"es_core_news_lg\") \n",
    "matcher = Matcher(pln.vocab)\n",
    "\n",
    "noun_adj_pattern = [{\"POS\": \"NOUN\"}, {\"POS\": {\"IN\": [\"NOUN\", \"ADJ\",\"PROPN\"]}}]\n",
    "noun_adj_pattern = [\n",
    "    {\"POS\": \"NOUN\"},\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"?\"},  # Optional common noun\n",
    "    {\"POS\": \"ADJ\", \"OP\": \"?\"},   # Optional adjective\n",
    "    {\"POS\": \"PROPN\", \"OP\": \"?\"},  # Optional proper noun\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"?\"}   # Optional common noun\n",
    "]\n",
    "#cada diccionario presenta un patron \n",
    "#El primer token debe ser un sustantivo (NOUN), \n",
    "#y el segundo token puede ser tanto un sustantivo como un adjetivo (NOUN o ADJ). \n",
    "matcher.add(\"noun_adj_fix\", [noun_adj_pattern])\n",
    "\n",
    "#Agregamos este patrón al objeto matcher con el nombre \"noun_adj_fix\".\n",
    "#Este es el nombre que le das al patrón. \n",
    "#Es un identificador único para este patrón en particular. Puedes elegir cualquier nombre que tenga sentido para ti.\n",
    "def NOUNS1(Texto):\n",
    "    tokens = pln(Texto)\n",
    "    Texto_corregido = Texto\n",
    "    matches = matcher(tokens)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        #span se refiere a una secuencia de tokens que se encuentra en una coincidencia particular en el texto. \n",
    "        #La estructura de span es una lista de objetos Token.\n",
    "        #Cada objeto Token en la lista representa una palabra individual del texto.\n",
    "        #Dado que estamos recorriendo coincidencias y span representa una secuencia de tokens que coincide con el patrón, \n",
    "        span = tokens[start:end]\n",
    "        span[-1].pos = pln.vocab.strings[\"NOUN\"] \n",
    "        #La razón por la que se utiliza span[-1] en esta línea de código es que estamos interesados en modificar la propiedad de POS \n",
    "        # del último token en la secuencia span. \n",
    "        #span[-1] es el ultimo elemento de la lista, accedemos al ultimo token\n",
    "        #en la secuencia que representa la coincidencia actual \n",
    "        #el último token en esa secuencia es el que queremos modificar.\n",
    "        #Despues accedemos al vocabulario y obteniendo el valor numerico que corresponde ala etiqueta pos [NOUN] utilizamos \n",
    "        #[\"NOUN\"] como clave de nuestro diccionario string\n",
    "    for i in range(len(tokens)):\n",
    "        print(\"Texto: \", tokens[i].text) #extrer el texto del token \n",
    "        print(\"PoS: \", tokens[i].pos_) #extraer el part of speech\n",
    "        #print(\"Lemma: \", tokens[i].lemma_) #extraer la lematización \n",
    "        #print(\"\\n\")\n",
    "        if i + 1 < len(tokens): # ADD CASE FOR WHEN DETECTED AS PROPN\n",
    "            if tokens[i].pos_  == \"NOUN\" and tokens[i+1].pos_ == \"NOUN\" or tokens[i].pos_  == \"PROPN\" and tokens[i+1].pos_ == \"PROPN\":  \n",
    "                add = \"y\"\n",
    "                noun1 = f'{add} {tokens[i+1]}'\n",
    "                Texto_corregido = Texto_corregido.replace(tokens[i+1].text, noun1)  \n",
    "\n",
    "\n",
    "    return Texto_corregido \n",
    "\n",
    "Texto1 =\"Juega el perro gato en el parque y yo estoy con mi amigo Pedro.\"\n",
    "Texto2 = \"El perro gato es azul\"\n",
    "Texto3 = \"La mariposa gusano \"\n",
    "Texto4 = \"Mi amigo Pedro quiere ir al cine\"\n",
    "NOUNS1(Texto4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQcemrD14RIT"
   },
   "outputs": [],
   "source": [
    "# El siguiente código debe de poder ser ejecutado y obtener una respuesta que\n",
    "# muestre cláramente la diferencia entre el texto inicial y el corregido\n",
    "\n",
    "# Cada método deberá marcar el lugar donde encuentre un error con corchetes\n",
    "# e imprimir una lista con los errores encontrados\n",
    "\n",
    "Utterance = input(\"Texto para revisión: \\n\")\n",
    "\n",
    "# Pipeline de funciones definidas previamente\n",
    "Texto_Corregido = NOUNS(MAYUSC_MINUSC(PALABRA_REPETIDA(TIEMPOS_VERBALES(ERRORES_COMUNES((Utterance))))))\n",
    "\n",
    "print('\\nTexto corregido:\\n' + Texto_Corregido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQXt2ZvN4RIU"
   },
   "outputs": [],
   "source": [
    "# Frases que puedes probar:\n",
    "# ola, me das mi zaldo por fabor, grasias\n",
    "# Quiero una casas en la playa\n",
    "# los niño salieron a jugar al patio\n",
    "# Palabras que se repiten repiten\n",
    "\n",
    "# ola señorita, me puede dar mi zaldo por fabor, grasias, lo que pasa pasa es que quiero Comprar una casas en la playa playa para que los niño jueguen en el patio. Mi PeRRo es muy juguetón, por eso me mudo a la CDMX. EL casero mE dijo: \"debes pagado antes del viernes viernes\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
